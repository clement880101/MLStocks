{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "MSFT only LSTM RNN Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bj-RYwG4wAp"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLVs-cQRyXcF"
      },
      "source": [
        "#pip install keras-adabound"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_KYLFC3ZaS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "#from keras_adabound import AdaBound\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.metrics import mean_squared_error as calc_mse\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK_8g1JD3n7X",
        "outputId": "74d9a8bd-c858-48c0-b0d1-77b13efbfe4f"
      },
      "source": [
        "csv = pd.read_csv('https://raw.githubusercontent.com/clement880101/MLStocks/master/Msft.csv', date_parser= True)\n",
        "csv.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'Msft_open', 'Msft_high', 'Msft_low', 'Msft_close',\n",
              "       'Msft_adjusted_close', 'Msft_volume', 'Msft_dividend',\n",
              "       'Msft_split_coefficent', 'Msft_Real Middle Band',\n",
              "       'Msft_Real Upper Band', 'Msft_Real Lower Band', 'Msft_MACD',\n",
              "       'Msft_MACD_Hist', 'Msft_MACD_Signal', 'Msft_RSI', 'Msft_CCI',\n",
              "       'Msft_Aroon Down', 'Msft_Aroon Up', 'Msft_Chaikin A/D', 'Msft_ADX',\n",
              "       'Msft_SMA', 'SPY_open', 'SPY_high', 'SPY_low', 'SPY_close',\n",
              "       'SPY_adjusted_close', 'SPY_volume', 'SPY_dividend',\n",
              "       'SPY_split_coefficent'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3FCJbL04z5f"
      },
      "source": [
        "# Recurrent LSTM Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsplEzCFFHa"
      },
      "source": [
        "###help functions / RNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DTRQx4bO3V8"
      },
      "source": [
        "#helper functions\n",
        "def to_dataframe(csv):\n",
        "    # returns dataframe\n",
        "    df = pd.read_csv(csv, date_parser=True)\n",
        "    return df\n",
        "\n",
        "def reverse_order(df):\n",
        "    # reverse order of data so earliest day is day 0\n",
        "    reversed_df = df[::-1].reset_index(drop=True)\n",
        "    return reversed_df\n",
        "\n",
        "def remove_dates(df):\n",
        "  #stores dates in a dictionary\n",
        "  dates = {}\n",
        "  for i in range(df.shape[0]):\n",
        "    date = df.iloc[i]['date']\n",
        "    dates[date] = i\n",
        "\n",
        "  df = df.drop(['date'],axis=1)\n",
        "\n",
        "  return dates, df\n",
        "\n",
        "def scale_data(df, target_column):\n",
        "    # scale data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # save this value to convert stock prediction to nominal data\n",
        "    upscale_value = 1 / scaler.scale_[target_column]\n",
        "    return scaled_data, scaler, upscale_value\n",
        "\n",
        "def split_data(df, date_value):\n",
        "  df_before = df[df['date'] < date_value].copy()\n",
        "  df_after = df[df['date'] >= date_value].copy()\n",
        "  return df_before, df_after\n",
        "\n",
        "def create_xy(data, scope, target_column):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(scope, data.shape[0]):\n",
        "    # the xTest will have an array of the last x \"scope\" days of data\n",
        "    # yTest will be the the opening value of the next day\n",
        "    x.append(data[i-scope:i])\n",
        "    y.append(data[i,target_column])\n",
        "  \n",
        "  #the length of x is the data length - scope \n",
        "  #in each x there is a batch size of x \"scope\" points\n",
        "  return np.array(x), np.array(y)\n",
        "#recurrent neural network\n",
        "\n",
        "class Rnn:\n",
        "    # set values for Rnn object\n",
        "    def __init__(self, rows_size, columns_size):\n",
        "        self.rows = rows_size\n",
        "        self.columns = columns_size\n",
        "        self.model = None\n",
        "        self.logs = None\n",
        "\n",
        "\n",
        "    # train function for Rnn class\n",
        "    def structure(self, layers, units_for_layers, dropouts_for_layers):\n",
        "        #initilize Sequential rnn\n",
        "        self.model = Sequential()\n",
        "        # add first layer and define input shape\n",
        "        self.model.add(LSTM(units_for_layers[0], activation = 'relu', return_sequences = True, input_shape = (self.rows, self.columns)))\n",
        "        self.model.add(Dropout(dropouts_for_layers[0]))\n",
        "        # for adding additional layers\n",
        "        if layers > 2:\n",
        "            for i in range(1,layers):\n",
        "\n",
        "                return_setting = True\n",
        "                #dont need to return values upstream on last layer\n",
        "                if i == layers - 1: return_setting = False\n",
        "\n",
        "                self.model.add(LSTM(units_for_layers[i], activation = 'relu', return_sequences = return_setting))\n",
        "                self.model.add(Dropout(dropouts_for_layers[i]))\n",
        "\n",
        "\n",
        "        #final endpoint for rnn layers\n",
        "        self.model.add(Dense(units = 1))\n",
        "        return None\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "      \n",
        "    def history(self):\n",
        "      return self.model.history\n",
        "\n",
        "    def train(self, xTrain, yTrain, epochs, batch_size, optimizer, file_name, ada_low_lr = None, ada_high_lr = None):\n",
        "        #compiles model that was created\n",
        "        if optimizer != 'adaboost':\n",
        "            self.model.compile(optimizer=optimizer, loss = 'mean_squared_error')\n",
        "        else:\n",
        "            self.model.compile(optimizer= AdaBound(lr=ada_low_lr, final_lr=ada_high_lr), loss = 'mean_squared_error')\n",
        "\n",
        "        #create log for getting stats\n",
        "        CSV_logger = CSVLogger(file_name + '.csv',separator=',',append=False)\n",
        "        #fit model to data\n",
        "        self.model.fit(xTrain, yTrain, epochs=epochs, batch_size=batch_size, callbacks=[CSV_logger])\n",
        "        self.logs = CSV_logger\n",
        "        return None\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        y_hat = self.model.predict(input_data)\n",
        "        return y_hat"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW5XVpxQqJQS"
      },
      "source": [
        "def create_file_name(array):\n",
        "  string = 'Stats'\n",
        "  for item in array:\n",
        "    string = string + '_' + str(item)\n",
        "  return string"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjkVODqFGxH"
      },
      "source": [
        "###main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8s9JwntT-sh"
      },
      "source": [
        "#arrange df and split by date\n",
        "df = reverse_order(csv)\n",
        "training_data, test_data = split_data(df, '2018-01-01')\n",
        "\n",
        "#store date labels and drop columns \n",
        "dates_train, training_data = remove_dates(training_data)\n",
        "dates_test, test_data = remove_dates(test_data)\n",
        "\n",
        "target_column = 5 #this is MSFT adjusted column\n",
        "#scale_data on training data and get scaler with value\n",
        "training_data, scaler, upscale_value = scale_data(training_data, target_column-1)\n",
        "test_data = scaler.transform(test_data)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9a5DnZeM0oo"
      },
      "source": [
        "#create xTrain,yTrain.. and xTest,yTest\n",
        "#each x in xTrain will be an array of x days\n",
        "xTrain, yTrain = create_xy(training_data, 5, target_column-1)\n",
        "xTest, yTest = create_xy(test_data, 5, target_column-1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L9h7Sr2t0AZ"
      },
      "source": [
        "###Params loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0x2VyUipgVO"
      },
      "source": [
        "#batch dimensions\n",
        "row_size = xTrain.shape[1]\n",
        "column_size = xTrain.shape[2]\n",
        "# params to test\n",
        "layers = [3,5]\n",
        "epochs = [10, 25, 50]\n",
        "batches = [100, 200]\n",
        "optimizer = 'adam'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOno0G7ZqCiQ"
      },
      "source": [
        "params = []\n",
        "csv_name = 'MSFT'\n",
        "\n",
        "for l in layers:\n",
        "  units = []\n",
        "  dropouts = []\n",
        "  for i in range(l):\n",
        "    units.append(column_size)\n",
        "    if i == 0:\n",
        "      dropouts.append(0.2)\n",
        "    else: \n",
        "      dropouts.append(0.5)\n",
        "\n",
        "  for e in epochs:\n",
        "    for b in batches:\n",
        "      file_name = create_file_name([csv_name,l,e,b])\n",
        "      params.append({'layers': l,'epochs': e,'batches': b, 'units': units, 'dropouts': dropouts, 'optimizer': optimizer, 'file_name': file_name})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c2f1tiB3uXt9",
        "outputId": "a14c5b4b-0855-4b23-8be3-398e0a503fed"
      },
      "source": [
        "params[0]['file_name']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Stats_MSFT_3_10_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWCFHd6juIY-"
      },
      "source": [
        "### Create evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SDAaeLKucDd",
        "outputId": "19b90393-fc18-40b8-c771-756279c38fa2"
      },
      "source": [
        "#track_time_to_train\n",
        "time_training = []\n",
        "networks = []\n",
        "for param in params:\n",
        "  t0 = time.clock()\n",
        "  #Steps for rnn:\n",
        "  #1. initialize, #2. structure, #train, #summary, #predict\n",
        "  print('Starting this param'), print(param)\n",
        "  nnet = Rnn(row_size,column_size)\n",
        "  nnet.structure(param['layers'], param['units'], param['dropouts'])\n",
        "  nnet.train(xTrain, yTrain, param['epochs'],param['batches'],param['optimizer'],param['file_name'])\n",
        "  networks.append(nnet)\n",
        "  t1 = time.clock()\n",
        "  time_training.append(t1-t0)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting this param\n",
            "{'layers': 3, 'epochs': 10, 'batches': 100, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_10_100'}\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0352\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.0108\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0083\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0074\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0070\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0066\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0061\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0064\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0051\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0052\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 10, 'batches': 200, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_10_200'}\n",
            "Epoch 1/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0681\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0288\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0177\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0110\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0093\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0081\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0077\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0075\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0079\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0071\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 25, 'batches': 100, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_25_100'}\n",
            "Epoch 1/25\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0350\n",
            "Epoch 2/25\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0124\n",
            "Epoch 3/25\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0085\n",
            "Epoch 4/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0076\n",
            "Epoch 5/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0070\n",
            "Epoch 6/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0060\n",
            "Epoch 7/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0057\n",
            "Epoch 8/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0050\n",
            "Epoch 9/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0050\n",
            "Epoch 10/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0052\n",
            "Epoch 11/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0048\n",
            "Epoch 12/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0045\n",
            "Epoch 13/25\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0048\n",
            "Epoch 14/25\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0046\n",
            "Epoch 15/25\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0040\n",
            "Epoch 16/25\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0042\n",
            "Epoch 17/25\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0040\n",
            "Epoch 18/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0043\n",
            "Epoch 19/25\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0038\n",
            "Epoch 20/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0038\n",
            "Epoch 21/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0037\n",
            "Epoch 22/25\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0041\n",
            "Epoch 23/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0036\n",
            "Epoch 24/25\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0041\n",
            "Epoch 25/25\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0037\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 25, 'batches': 200, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_25_200'}\n",
            "Epoch 1/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0509\n",
            "Epoch 2/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0199\n",
            "Epoch 3/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0135\n",
            "Epoch 4/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0109\n",
            "Epoch 5/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0094\n",
            "Epoch 6/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0078\n",
            "Epoch 7/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0072\n",
            "Epoch 8/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0073\n",
            "Epoch 9/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0065\n",
            "Epoch 10/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0066\n",
            "Epoch 11/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0060\n",
            "Epoch 12/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0055\n",
            "Epoch 13/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0058\n",
            "Epoch 14/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0055\n",
            "Epoch 15/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0050\n",
            "Epoch 16/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0049\n",
            "Epoch 17/25\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0052\n",
            "Epoch 18/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0048\n",
            "Epoch 19/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0047\n",
            "Epoch 20/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0046\n",
            "Epoch 21/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0042\n",
            "Epoch 22/25\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0042\n",
            "Epoch 23/25\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0041\n",
            "Epoch 24/25\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0039\n",
            "Epoch 25/25\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0049\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 50, 'batches': 100, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_50_100'}\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0289\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0097\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.0066\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0062\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0055\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0050\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0048\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0042\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0046\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0036\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0037\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0038\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0036\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.0039\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0042\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0036\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0038\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0033\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0035\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0035\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0031\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0030\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0031\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0033\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0027\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0032\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0029\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0030\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0029\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0030\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0033\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0028\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0028\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0029\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0029\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0027\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0028\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0028\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0028\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0028\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0028\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0027\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0028\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0025\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0026\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0027\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0027\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0027\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.0025\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.0029\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 50, 'batches': 200, 'units': [29, 29, 29], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_3_50_200'}\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0476\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0108\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0085\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0079\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0074\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0068\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0059\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0059\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0062\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0054\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0051\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0049\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0045\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0044\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0044\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0047\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0039\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0043\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0041\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0038\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0040\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0041\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0037\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0037\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0036\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0036\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0036\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0032\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0036\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0034\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0032\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0034\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0033\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0031\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0032\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0033\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0034\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0034\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0033\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0034\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0031\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0033\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0033\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0031\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0031\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0030\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0031\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 10, 'batches': 100, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_10_100'}\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0523\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0236\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0155\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0112\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0091\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0090\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0076\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0074\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0067\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0064\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 10, 'batches': 200, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_10_200'}\n",
            "Epoch 1/10\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0666\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0345\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0282\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0196\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0148\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0127\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0115\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0102\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0096\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0089\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 25, 'batches': 100, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_25_100'}\n",
            "Epoch 1/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0497\n",
            "Epoch 2/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0205\n",
            "Epoch 3/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0159\n",
            "Epoch 4/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0117\n",
            "Epoch 5/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0092\n",
            "Epoch 6/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0085\n",
            "Epoch 7/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0081\n",
            "Epoch 8/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0076\n",
            "Epoch 9/25\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0069\n",
            "Epoch 10/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0068\n",
            "Epoch 11/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0060\n",
            "Epoch 12/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0058\n",
            "Epoch 13/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0056\n",
            "Epoch 14/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0054\n",
            "Epoch 15/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0053\n",
            "Epoch 16/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0051\n",
            "Epoch 17/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0047\n",
            "Epoch 18/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0050\n",
            "Epoch 19/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0050\n",
            "Epoch 20/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0046\n",
            "Epoch 21/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0047\n",
            "Epoch 22/25\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0045\n",
            "Epoch 23/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0047\n",
            "Epoch 24/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0045\n",
            "Epoch 25/25\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0043\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 25, 'batches': 200, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_25_200'}\n",
            "Epoch 1/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0635\n",
            "Epoch 2/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0296\n",
            "Epoch 3/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0205\n",
            "Epoch 4/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0141\n",
            "Epoch 5/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0129\n",
            "Epoch 6/25\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0104\n",
            "Epoch 7/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0095\n",
            "Epoch 8/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0097\n",
            "Epoch 9/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0096\n",
            "Epoch 10/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0092\n",
            "Epoch 11/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0077\n",
            "Epoch 12/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0072\n",
            "Epoch 13/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0072\n",
            "Epoch 14/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0068\n",
            "Epoch 15/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0067\n",
            "Epoch 16/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0063\n",
            "Epoch 17/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0061\n",
            "Epoch 18/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0064\n",
            "Epoch 19/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0060\n",
            "Epoch 20/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0056\n",
            "Epoch 21/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0062\n",
            "Epoch 22/25\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0055\n",
            "Epoch 23/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0056\n",
            "Epoch 24/25\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0056\n",
            "Epoch 25/25\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0056\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 50, 'batches': 100, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_50_100'}\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0482\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0229\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0148\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0144\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0096\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0079\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0086\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0078\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0076\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0067\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0062\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.0067\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0057\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0055\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0055\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0059\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0055\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0048\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0048\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0047\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0048\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0050\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0046\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0043\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0049\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0046\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0046\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0046\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0044\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0042\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0044\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0045\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0041\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0043\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0040\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0044\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0044\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0043\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.0038\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0039\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0042\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0040\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.0041\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0043\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0040\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0037\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0040\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0036\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0041\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.0038\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 50, 'batches': 200, 'units': [29, 29, 29, 29, 29], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_5_50_200'}\n",
            "Epoch 1/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0596\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0292\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0205\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0153\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0117\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0097\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0088\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0081\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0074\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0071\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0072\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0063\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0065\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0056\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0062\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0055\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0050\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0051\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0049\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0047\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0048\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0044\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0042\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0040\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0045\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0042\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0044\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0049\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0043\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0041\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0038\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0042\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0042\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0043\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0038\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0037\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0043\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0041\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0037\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0038\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0039\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0038\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0036\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0039\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk6Ds-8BEttj"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrLmBIP326yY"
      },
      "source": [
        "Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4L6nFAoFdR_"
      },
      "source": [
        "def save_test_image(yTest, y_pred, file_name):\n",
        "  plt.plot(yTest, color='black', label='Actual')\n",
        "  plt.plot(y_pred, color='red', label='Predict')\n",
        "  plt.title('Testing')\n",
        "  plt.xlabel('time [days]')\n",
        "  plt.ylabel('price')\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(fname = (file_name +'_test_img.jpg'))\n",
        "  plt.close()\n",
        "  return None"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za8f2V9GGDqL"
      },
      "source": [
        "def save_train_image(yTrain, y_pred, file_name):\n",
        "  plt.plot(yTrain, color='black', label='Actual')\n",
        "  plt.plot(y_pred, color='red', label='Predict')\n",
        "  plt.title('Training')\n",
        "  plt.xlabel('time [days]')\n",
        "  plt.ylabel('price')\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(fname = (file_name+'_train_img.jpg'))\n",
        "  plt.close()\n",
        "  return None"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F49cLqLLcVL",
        "outputId": "a74216be-8ea1-4142-84c0-c4a101336fea"
      },
      "source": [
        "time_training"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.781369000000002,\n",
              " 9.013605000000002,\n",
              " 24.04926,\n",
              " 17.516650000000006,\n",
              " 45.746174999999994,\n",
              " 32.02353599999999,\n",
              " 18.646477000000004,\n",
              " 14.909222999999997,\n",
              " 39.22663699999998,\n",
              " 28.986884000000003,\n",
              " 72.069167,\n",
              " 51.97744399999999]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPr2fu4R255W"
      },
      "source": [
        "time_evaluating = []\n",
        "header = ['file_name: layers, epoch, batch', 'mse_scaled', 'mse_unscaled', 'overall_time']\n",
        "results = []\n",
        "yTest_scaled = yTest * upscale_value\n",
        "yTrain_scaled = yTrain * upscale_value\n",
        "\n",
        "for i in range(len(networks)):\n",
        "  t0 = time.clock()\n",
        "  nnet = networks[i]\n",
        "  file_name = params[i]['file_name']\n",
        "  #test images and result\n",
        "  yPred_test = nnet.predict(xTest)\n",
        "  yPred_test_scaled = yPred_test * upscale_value\n",
        "  save_test_image(yTest_scaled, yPred_test_scaled, file_name)\n",
        "\n",
        "  mse_unscaled = calc_mse(yTest, yPred_test)\n",
        "  mse_scaled = calc_mse(yTest_scaled, yPred_test_scaled)\n",
        "\n",
        "  #training images\n",
        "  yPred_train = nnet.predict(xTrain)\n",
        "  yPred_train_scaled = yPred_train * upscale_value\n",
        "  save_train_image(yTrain_scaled, yPred_train_scaled, file_name)\n",
        "  t1 = time.clock()\n",
        "\n",
        "  time_evaluating = t1-t0\n",
        "  overall_time = time_training[i] + time_evaluating\n",
        "  stats = [file_name, round(mse_scaled,3), round(mse_unscaled,3), round(overall_time, 3)]\n",
        "  results.append(stats)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcchXmPFOHam"
      },
      "source": [
        "results_df = pd.DataFrame(data = results, columns= header)\n",
        "results_df.to_csv('LSTM_' + csv_name+'_results.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D0nnUxonRJz4",
        "outputId": "cda0cfb4-cf2e-42ad-a294-2651637a8507"
      },
      "source": [
        "!zip -r /content/file.zip /content/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2020.12.02/ (stored 0%)\n",
            "  adding: content/.config/logs/2020.12.02/22.03.37.873126.log (deflated 91%)\n",
            "  adding: content/.config/logs/2020.12.02/22.04.13.854338.log (deflated 87%)\n",
            "  adding: content/.config/logs/2020.12.02/22.04.21.823807.log (deflated 54%)\n",
            "  adding: content/.config/logs/2020.12.02/22.03.59.234441.log (deflated 53%)\n",
            "  adding: content/.config/logs/2020.12.02/22.04.37.441505.log (deflated 54%)\n",
            "  adding: content/.config/logs/2020.12.02/22.04.38.150307.log (deflated 54%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/.metricsUUID (stored 0%)\n",
            "  adding: content/Stats_MSFT_5_25_200_train_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_3_25_200_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_25_200_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_50_200_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_25_200.csv (deflated 50%)\n",
            "  adding: content/Stats_MSFT_5_25_200.csv (deflated 49%)\n",
            "  adding: content/Stats_MSFT_3_10_200.csv (deflated 41%)\n",
            "  adding: content/Stats_MSFT_5_25_100.csv (deflated 50%)\n",
            "  adding: content/Stats_MSFT_3_50_200_train_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_5_10_200_train_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_5_50_100_train_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_3_50_100_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_50_100_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_25_100_train_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_3_25_100.csv (deflated 50%)\n",
            "  adding: content/Stats_MSFT_3_25_100_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_10_100_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_25_200_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_10_100.csv (deflated 41%)\n",
            "  adding: content/Stats_MSFT_3_25_100_test_img.jpg (deflated 12%)\n",
            "  adding: content/Stats_MSFT_5_10_200.csv (deflated 41%)\n",
            "  adding: content/Stats_MSFT_5_50_100_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_50_200.csv (deflated 53%)\n",
            "  adding: content/Stats_MSFT_3_10_100_test_img.jpg (deflated 12%)\n",
            "  adding: content/Stats_MSFT_5_10_100_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_10_200_test_img.jpg (deflated 12%)\n",
            "  adding: content/LSTM_MSFT_results.csv (deflated 51%)\n",
            "  adding: content/Stats_MSFT_5_50_200.csv (deflated 52%)\n",
            "  adding: content/Stats_MSFT_3_10_200_test_img.jpg (deflated 14%)\n",
            "  adding: content/Stats_MSFT_3_10_200_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_50_200_train_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_10_100.csv (deflated 42%)\n",
            "  adding: content/Stats_MSFT_5_50_100.csv (deflated 53%)\n",
            "  adding: content/Stats_MSFT_3_50_100.csv (deflated 53%)\n",
            "  adding: content/Stats_MSFT_5_25_100_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_3_50_200_test_img.jpg (deflated 13%)\n",
            "  adding: content/Stats_MSFT_5_10_100_test_img.jpg (deflated 11%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/README.md (deflated 42%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2a0de9cf-65eb-4dc7-8983-c094f9bbca24\", \"file.zip\", 7624695)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}