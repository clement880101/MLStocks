{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "MSFT_Combined LSTM_RNN_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bj-RYwG4wAp"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLVs-cQRyXcF",
        "outputId": "c177bf4c-78b5-4f6c-cdd4-1e9db0882db6"
      },
      "source": [
        "pip install keras-adabound"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-adabound\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/74/85de8379eba8e0f819ef9b62ff32d24a3f624758800e12bd9572e3afb546/keras-adabound-0.6.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-adabound) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-adabound) (2.4.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from keras-adabound) (2.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-adabound) (1.15.0)\n",
            "Building wheels for collected packages: keras-adabound\n",
            "  Building wheel for keras-adabound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-adabound: filename=keras_adabound-0.6.0-cp36-none-any.whl size=6608 sha256=5e42fb69e4287aaedf9f10ff9938d4e867e1dc55acf49f009e251ba8fa4dca85\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/81/9c/04af926d62bddd280c97af1704a9baaef511664b56865958e8\n",
            "Successfully built keras-adabound\n",
            "Installing collected packages: keras-adabound\n",
            "Successfully installed keras-adabound-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_KYLFC3ZaS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "#from keras_adabound import AdaBound\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU\n",
        "from sklearn.metrics import mean_squared_error as calc_mse\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK_8g1JD3n7X",
        "outputId": "936d18e4-fd38-480c-c1e3-93738875260d"
      },
      "source": [
        "csv = pd.read_csv('https://raw.githubusercontent.com/clement880101/MLStocks/master/Combined_Stock_Data_MSFT.csv', date_parser= True)\n",
        "csv.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'Msft_open', 'Msft_high', 'Msft_low', 'Msft_close',\n",
              "       'Msft_adjusted_close', 'Msft_volume', 'Msft_dividend',\n",
              "       'Msft_split_coefficent', 'Msft_Real Middle Band',\n",
              "       ...\n",
              "       'Amzn_ADX', 'Amzn_SMA', 'SPY_open', 'SPY_high', 'SPY_low', 'SPY_close',\n",
              "       'SPY_adjusted_close', 'SPY_volume', 'SPY_dividend',\n",
              "       'SPY_split_coefficent'],\n",
              "      dtype='object', length=114)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3FCJbL04z5f"
      },
      "source": [
        "# Recurrent LSTM Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsplEzCFFHa"
      },
      "source": [
        "###help functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DTRQx4bO3V8"
      },
      "source": [
        "#helper functions\n",
        "def to_dataframe(csv):\n",
        "    # returns dataframe\n",
        "    df = pd.read_csv(csv, date_parser=True)\n",
        "    return df\n",
        "\n",
        "def reverse_order(df):\n",
        "    # reverse order of data so earliest day is day 0\n",
        "    reversed_df = df[::-1].reset_index(drop=True)\n",
        "    return reversed_df\n",
        "\n",
        "def remove_dates(df):\n",
        "  #stores dates in a dictionary\n",
        "  dates = {}\n",
        "  for i in range(df.shape[0]):\n",
        "    date = df.iloc[i]['date']\n",
        "    dates[date] = i\n",
        "\n",
        "  df = df.drop(['date'],axis=1)\n",
        "\n",
        "  return dates, df\n",
        "\n",
        "def scale_data(df, target_column):\n",
        "    # scale data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # save this value to convert stock prediction to nominal data\n",
        "    upscale_value = 1 / scaler.scale_[target_column]\n",
        "    return scaled_data, scaler, upscale_value\n",
        "\n",
        "def split_data(df, date_value):\n",
        "  df_before = df[df['date'] < date_value].copy()\n",
        "  df_after = df[df['date'] >= date_value].copy()\n",
        "  return df_before, df_after\n",
        "\n",
        "def create_xy(data, scope, target_column):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(scope, data.shape[0]):\n",
        "    # the xTest will have an array of the last x \"scope\" days of data\n",
        "    # yTest will be the the opening value of the next day\n",
        "    x.append(data[i-scope:i])\n",
        "    y.append(data[i,target_column])\n",
        "  \n",
        "  #the length of x is the data length - scope \n",
        "  #in each x there is a batch size of x \"scope\" points\n",
        "  return np.array(x), np.array(y)\n",
        "#recurrent neural network\n",
        "\n",
        "class Rnn:\n",
        "    # set values for Rnn object\n",
        "    def __init__(self, rows_size, columns_size):\n",
        "        self.rows = rows_size\n",
        "        self.columns = columns_size\n",
        "        self.model = None\n",
        "        self.logs = None\n",
        "\n",
        "\n",
        "    # train function for Rnn class\n",
        "    def structure(self, layers, units_for_layers, dropouts_for_layers):\n",
        "        #initilize Sequential rnn\n",
        "        self.model = Sequential()\n",
        "        # add first layer and define input shape\n",
        "        self.model.add(LSTM(units_for_layers[0], activation = 'relu', return_sequences = True, input_shape = (self.rows, self.columns)))\n",
        "        self.model.add(Dropout(dropouts_for_layers[0]))\n",
        "        # for adding additional layers\n",
        "        if layers > 2:\n",
        "            for i in range(1,layers):\n",
        "\n",
        "                return_setting = True\n",
        "                #dont need to return values upstream on last layer\n",
        "                if i == layers - 1: return_setting = False\n",
        "\n",
        "                self.model.add(LSTM(units_for_layers[i], activation = 'relu', return_sequences = return_setting))\n",
        "                self.model.add(Dropout(dropouts_for_layers[i]))\n",
        "\n",
        "\n",
        "        #final endpoint for rnn layers\n",
        "        self.model.add(Dense(units = 1))\n",
        "        return None\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "      \n",
        "    def history(self):\n",
        "      return self.model.history\n",
        "\n",
        "    def train(self, xTrain, yTrain, epochs, batch_size, optimizer, file_name, ada_low_lr = None, ada_high_lr = None):\n",
        "        #compiles model that was created\n",
        "        if optimizer != 'adaboost':\n",
        "            self.model.compile(optimizer=optimizer, loss = 'mean_squared_error')\n",
        "        else:\n",
        "            self.model.compile(optimizer= AdaBound(lr=ada_low_lr, final_lr=ada_high_lr), loss = 'mean_squared_error')\n",
        "\n",
        "        #create log for getting stats\n",
        "        CSV_logger = CSVLogger(file_name + '.csv',separator=',',append=False)\n",
        "        #fit model to data\n",
        "        self.model.fit(xTrain, yTrain, epochs=epochs, batch_size=batch_size, callbacks=[CSV_logger])\n",
        "        self.logs = CSV_logger\n",
        "        return None\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        y_hat = self.model.predict(input_data)\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW5XVpxQqJQS"
      },
      "source": [
        "def create_file_name(array):\n",
        "  string = 'Stats'\n",
        "  for item in array:\n",
        "    string = string + '_' + str(item)\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjkVODqFGxH"
      },
      "source": [
        "###main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8s9JwntT-sh"
      },
      "source": [
        "#arrange df and split by date\n",
        "df = reverse_order(csv)\n",
        "training_data, test_data = split_data(df, '2018-01-01')\n",
        "\n",
        "#store date labels and drop columns \n",
        "dates_train, training_data = remove_dates(training_data)\n",
        "dates_test, test_data = remove_dates(test_data)\n",
        "\n",
        "target_column = 5 #this is MSFT adjusted column\n",
        "#scale_data on training data and get scaler with value\n",
        "training_data, scaler, upscale_value = scale_data(training_data, target_column-1)\n",
        "test_data = scaler.transform(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9a5DnZeM0oo"
      },
      "source": [
        "#create xTrain,yTrain.. and xTest,yTest\n",
        "#each x in xTrain will be an array of x days\n",
        "xTrain, yTrain = create_xy(training_data, 5, target_column-1)\n",
        "xTest, yTest = create_xy(test_data, 5, target_column-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L9h7Sr2t0AZ"
      },
      "source": [
        "###Params loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0x2VyUipgVO"
      },
      "source": [
        "#batch dimensions\n",
        "row_size = xTrain.shape[1]\n",
        "column_size = xTrain.shape[2]\n",
        "# params to test\n",
        "layers = [3,5]\n",
        "epochs = [10, 25, 50]\n",
        "batches = [100, 200]\n",
        "optimizer = 'adam'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOno0G7ZqCiQ"
      },
      "source": [
        "params = []\n",
        "csv_name = 'MSFT_CSD'\n",
        "\n",
        "for l in layers:\n",
        "  units = []\n",
        "  dropouts = []\n",
        "  for i in range(l):\n",
        "    units.append(column_size)\n",
        "    if i == 0:\n",
        "      dropouts.append(0.2)\n",
        "    else: \n",
        "      dropouts.append(0.5)\n",
        "\n",
        "  for e in epochs:\n",
        "    for b in batches:\n",
        "      file_name = create_file_name([csv_name,l,e,b])\n",
        "      params.append({'layers': l,'epochs': e,'batches': b, 'units': units, 'dropouts': dropouts, 'optimizer': optimizer, 'file_name': file_name})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c2f1tiB3uXt9",
        "outputId": "21142d0c-a4ed-4d26-8849-42730d760e5d"
      },
      "source": [
        "params[0]['file_name']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Stats_MSFT_CSD_3_10_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWCFHd6juIY-"
      },
      "source": [
        "### Create evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SDAaeLKucDd",
        "outputId": "00dbbd7d-8731-4bf6-811e-b4e0862c1c10"
      },
      "source": [
        "#track_time_to_train\n",
        "time_training = []\n",
        "networks = []\n",
        "for param in params:\n",
        "  t0 = time.clock()\n",
        "  #Steps for rnn:\n",
        "  #1. initialize, #2. structure, #train, #summary, #predict\n",
        "  print('Starting this param'), print(param)\n",
        "  nnet = Rnn(row_size,column_size)\n",
        "  nnet.structure(param['layers'], param['units'], param['dropouts'])\n",
        "  nnet.train(xTrain, yTrain, param['epochs'],param['batches'],param['optimizer'],param['file_name'])\n",
        "  networks.append(nnet)\n",
        "  t1 = time.clock()\n",
        "  time_training.append(t1-t0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting this param\n",
            "{'layers': 3, 'epochs': 10, 'batches': 100, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_10_100'}\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 33025.2812\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 20307.7988\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 14082.7168\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 26858.7383\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 27548.0293\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 51043.0547\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 21728.9570\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 16594.2285\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 20370.7578\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 46931.8711\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 10, 'batches': 200, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_10_200'}\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 9637.4316\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 6840.7217\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 32694.2598\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 84533.0781\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 10642.0967\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 2179.4080\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 13304.8467\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 42675.9922\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 22843.8281\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 42559.9961\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 25, 'batches': 100, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_25_100'}\n",
            "Epoch 1/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 11359.8105\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 20368.6504\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 35683.4531\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 17624.3730\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 738.3487\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 80649.8281\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 11365.2979\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 59048.4961\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 17573.0312\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 51692.7109\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 5329.7271\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 17297.0371\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 11204.5371\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 34272.0586\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 3485.7971\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 7685.2998\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 3299.0125\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 17257.0254\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 79168.5938\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 31265.5762\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 40835.0547\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 22520.0625\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 2395.2656\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 448.5481\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 16381.2070\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 25, 'batches': 200, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_25_200'}\n",
            "Epoch 1/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 7591.8491\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 14929.0449\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 13048.0508\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 27132.0020\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 14594.5635\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 24328.4434\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 10918.1602\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 100251.4453\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 43715.4609\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 43580.9492\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 19165.5234\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 40983.9141\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 4681.7876\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 4066.2920\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 20332.5586\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 9570.3857\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 12206.5186\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 15343.2480\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 13562.6396\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 1348.4083\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 555.1240\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 17876.7793\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 2009.1552\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 1469.6089\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 14612.3594\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 50, 'batches': 100, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_50_100'}\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 33784.6875\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 5247.7822\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 5257.8662\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 65059.4453\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 162.1245\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 68931.8516\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 35803.3750\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 15411.7705\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 4214.6064\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 26050.9434\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 23672.5703\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 7524.1265\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 1922.6298\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 14475.9736\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 18638.0625\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 17820.2656\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 9517.8252\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 5534.2080\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 8686.5381\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 1948.7820\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 8760.8750\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 4342.4053\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 46398.1797\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 7560.7568\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 9209.3799\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 4457.5063\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 249.0037\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 7719.7637\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 1228.7150\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 7932.2197\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 3303.9387\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 3352.3650\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 3690.9360\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 2596.0964\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 1566.1498\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 951.2718\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 7318.5977\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 272.6480\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 12925.1504\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 5632.7188\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 1890.6626\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 4165.1094\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 760.8588\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 893.6263\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 2722.5647\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 1481.0370\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 3737.2886\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 1828.6946\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 5343.6191\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 3306.6990\n",
            "Starting this param\n",
            "{'layers': 3, 'epochs': 50, 'batches': 200, 'units': [113, 113, 113], 'dropouts': [0.2, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_3_50_200'}\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 68276.7734\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 20331.5234\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 28462.2852\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 7954.0674\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 3511.3716\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 12923.2148\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 18373.7422\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 18040.6816\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 4682.1523\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 14559.9004\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 860.7570\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 26088.5898\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 15182.3604\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 18925.5293\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 15333.7754\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 22869.8340\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 260.3558\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 45092.2344\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 26809.8477\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 12654.5312\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 7964.5742\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 4203.3726\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 6654.9692\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 1208.2185\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 8150.8477\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 4446.5454\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 409.2086\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 14789.7373\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 12793.7070\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 973.4381\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 4980.8047\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 1622.8927\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 9909.9092\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 5804.1885\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 373.8717\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 10197.1289\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 25751.8828\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 5115.4185\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 6508.1050\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 9060.4287\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 4890.4707\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 83.0025\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 4593.4692\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 1627.8802\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 7511.8506\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 1708.4646\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 3373.7678\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 5328.5098\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 2440.6296\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 3524.7944\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 10, 'batches': 100, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_10_100'}\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 12177.7441\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 3382.8552\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1329.5353\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 4917.6279\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 2999.2317\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 3110.9375\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 20768.3730\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1665.8163\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 6367.1899\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 6154.4385\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 10, 'batches': 200, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_10_200'}\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 12413.4688\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 5628.9141\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 118ms/step - loss: 1962.3923\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 2588.4434\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 3506.3726\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 12156.2188\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 1514.1104\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 1290.0630\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 4299.9746\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 4102.7261\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 25, 'batches': 100, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_25_100'}\n",
            "Epoch 1/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 7727.6396\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 15513.1357\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 1168.5206\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 12463.0801\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 2271.0154\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 5798.6245\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1786.6223\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 31773.4043\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 8806.4688\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 15477.9932\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 15269.5684\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 844.8927\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 8733.1748\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 6470.2891\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 3101.4700\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 4139.7881\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 1293.6890\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 49395.0234\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 2112.1233\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 35887.8281\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 15653.1094\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 4020.6577\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 106.8413\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 23924.3926\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 1958.5048\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 25, 'batches': 200, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_25_200'}\n",
            "Epoch 1/25\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 11455.5889\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 7428.3677\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 1286.1331\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 164.3970\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 24598.3379\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 11577.8467\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 2270.2222\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 3009.5120\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 1713.3949\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 112.7746\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 1s 118ms/step - loss: 1831.5081\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 1s 122ms/step - loss: 1859.8918\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 8077.0352\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 3484.1541\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 1984.6848\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 116.8241\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 4903.5747\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 2481.7314\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 559.2902\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 1169.6317\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 3400.6055\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 1401.1692\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 1499.0701\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 1962.2268\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 1036.8540\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 50, 'batches': 100, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_50_100'}\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 3452.6138\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 16893.8809\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 3612.7366\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 2685.2004\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 13805.6338\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 2982.8022\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 12863.7852\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 7750.7432\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 10796.6621\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 6435.5605\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 33388.1328\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 18589.8613\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 4985.2324\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 14066.3955\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 10862.6494\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 4079.3784\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 288.6434\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 10768.0977\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 4485.3257\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 21482.6504\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 16418.9160\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 2689.5496\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 22656.6641\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 8843.3486\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 9862.9893\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 14854.2383\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 5482.0190\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 5159.3862\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 4886.1582\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 5018.0757\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1024.2985\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 1s 72ms/step - loss: 6096.3721\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 11696.0244\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 7942.4912\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 1s 72ms/step - loss: 9354.8447\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1358.4678\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 173.1438\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 14043.9121\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 3677.3503\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 2410.8198\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 1151.1792\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 9772.3740\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 626.4962\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 5824.9927\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 4159.9751\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 3871.1716\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 4401.7876\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 303.9898\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 3688.3555\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 2054.9568\n",
            "Starting this param\n",
            "{'layers': 5, 'epochs': 50, 'batches': 200, 'units': [113, 113, 113, 113, 113], 'dropouts': [0.2, 0.5, 0.5, 0.5, 0.5], 'optimizer': 'adam', 'file_name': 'Stats_MSFT_CSD_5_50_200'}\n",
            "Epoch 1/50\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 795.7900\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 13460.1953\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 3416.4534\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 9298.5186\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 271.3106\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 5554.1235\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 17519.2910\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 1593.8533\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 13589.6699\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 11559.8740\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 13643.5635\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 2694.3960\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 7019.7783\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 3565.9734\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 9095.4668\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 8290.1172\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 2141.6682\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 5480.3589\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 5589.1138\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 6410.2832\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 2185.1174\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 7876.5845\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 7103.9438\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 430.6731\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 195.0701\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 8790.4512\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 1s 107ms/step - loss: 10329.8506\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 1544.9845\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 4124.2856\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 1652.6039\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 7679.6465\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 4699.6978\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 979.6442\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 794.6658\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 1753.4131\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 5410.6865\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 1629.7261\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 563.1451\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 1760.7998\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 1253.3467\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 2040.7322\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 6579.0874\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 565.8025\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 1255.7826\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 2921.2471\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 1358.8358\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 171.6537\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 76.4879\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 4761.8423\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 2799.4729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk6Ds-8BEttj"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrLmBIP326yY"
      },
      "source": [
        "Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U4L6nFAoFdR_"
      },
      "source": [
        "def save_test_image(yTest, y_pred, file_name):\n",
        "  plt.plot(yTest, color='black', label='Actual')\n",
        "  plt.plot(y_pred, color='red', label='Predict')\n",
        "  plt.title('Testing')\n",
        "  plt.xlabel('time [days]')\n",
        "  plt.ylabel('price')\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(fname = (file_name +'_test_img.jpg'))\n",
        "  plt.close()\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Za8f2V9GGDqL"
      },
      "source": [
        "def save_train_image(yTrain, y_pred, file_name):\n",
        "  plt.plot(yTrain, color='black', label='Actual')\n",
        "  plt.plot(y_pred, color='red', label='Predict')\n",
        "  plt.title('Training')\n",
        "  plt.xlabel('time [days]')\n",
        "  plt.ylabel('price')\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(fname = (file_name+'_train_img.jpg'))\n",
        "  plt.close()\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8F49cLqLLcVL",
        "outputId": "f0d5a1d2-fcbf-41f4-9081-3de8f03fb03c"
      },
      "source": [
        "time_training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.649014999999999,\n",
              " 12.533528,\n",
              " 31.189546999999997,\n",
              " 26.369709999999998,\n",
              " 57.88372199999999,\n",
              " 48.36545100000001,\n",
              " 24.421193999999986,\n",
              " 21.057907999999998,\n",
              " 51.88860199999999,\n",
              " 44.69563400000004,\n",
              " 98.30523099999999,\n",
              " 80.91186799999997]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPr2fu4R255W"
      },
      "source": [
        "time_evaluating = []\n",
        "header = ['file_name: layers, epoch, batch', 'mse_scaled', 'mse_unscaled', 'overall_time']\n",
        "results = []\n",
        "yTest_scaled = yTest * upscale_value\n",
        "yTrain_scaled = yTrain * upscale_value\n",
        "\n",
        "for i in range(len(networks)):\n",
        "  t0 = time.clock()\n",
        "  nnet = networks[i]\n",
        "  file_name = params[i]['file_name']\n",
        "  #test images and result\n",
        "  yPred_test = nnet.predict(xTest)\n",
        "  yPred_test_scaled = yPred_test * upscale_value\n",
        "  save_test_image(yTest_scaled, yPred_test_scaled, file_name)\n",
        "\n",
        "  mse_unscaled = calc_mse(yTest, yPred_test)\n",
        "  mse_scaled = calc_mse(yTest_scaled, yPred_test_scaled)\n",
        "\n",
        "  #training images\n",
        "  yPred_train = nnet.predict(xTrain)\n",
        "  yPred_train_scaled = yPred_train * upscale_value\n",
        "  save_test_image(yTrain_scaled, yPred_train_scaled, file_name)\n",
        "  t1 = time.clock()\n",
        "\n",
        "  time_evaluating = t1-t0\n",
        "  overall_time = time_training[i] + time_evaluating\n",
        "  stats = [file_name, mse_scaled, mse_unscaled, overall_time]\n",
        "  results.append(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qcchXmPFOHam",
        "outputId": "5a283483-f388-4ffd-ac90-a23136189c6d"
      },
      "source": [
        "results_df = pd.DataFrame(data = results, columns= header)\n",
        "results_df.to_csv(csv_name+'_results.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    688\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 4 columns passed, passed data had 6 columns",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f12848416954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         return _list_of_dict_to_arrays(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 4 columns passed, passed data had 6 columns"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z7OFSsf0MsF6"
      },
      "source": [
        "!zip -r /content/file.zip /content/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtt9Ix2x4sQw"
      },
      "source": [
        "###Scrap code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fx9D56VS6Cm"
      },
      "source": [
        "# plt.figure(figsize=(14,5))\n",
        "# plt.plot(yTest, color = 'red', label = 'Actual MSFT Adj. Stock Price')\n",
        "# plt.plot(y_pred, color = 'blue', label = 'Predicted MSFT Adj. Stock Price')\n",
        "# plt.title('MSFT Stock Price Prediction')\n",
        "# plt.xlabel('Days')\n",
        "# plt.ylabel('MSFT Adj. Stock Price')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZdlJOzdQhhP"
      },
      "source": [
        "# date = '2020-01-01' \n",
        "# obj = datetime.datetime.strptime(date,\"%Y-%m-%d\") + timedelta(days=1)\n",
        "# datetime.datetime.strftime(obj, \"%Y-%m-%d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owz_c_S2QYBS"
      },
      "source": [
        "# def get_valid_date(value, dates, up_or_down):\n",
        "#   if value in dates:\n",
        "#     print('date was valid')\n",
        "#     return dates.get(value)\n",
        "\n",
        "#   if value not in dates:\n",
        "#     valid = False\n",
        "#     nearest_value = value\n",
        "#     while valid == False:\n",
        "#       if up_or_down == 'up':\n",
        "#         #increase days\n",
        "#         new_datetime = datetime.datetime.strptime(nearest_value,\"%Y-%m-%d\") + timedelta(days=1)\n",
        "#       else: \n",
        "#         new_datetime = datetime.datetime.strptime(nearest_value,\"%Y-%m-%d\") - timedelta(days=1)\n",
        "\n",
        "#       nearest_value = datetime.datetime.strftime(new_datetime, \"%Y-%m-%d\")\n",
        "#       if value in dates == True:\n",
        "#         valid == true\n",
        "#         print('The nearest valid date was' + value)\n",
        "#     return dates.get(nearest_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2coXUOT-Kkk"
      },
      "source": [
        "# y_pred =networks[0].predict(xTest)\n",
        "# y_pred = y_pred * upscale_value\n",
        "# yTest = yTest * upscale_value\n",
        "# print('Our mse error on the testing data is: ')\n",
        "# print(calc_mse(yTest, y_pred))\n",
        "\n",
        "# plt.plot(yTest, color='black', label='Actual')\n",
        "# plt.plot(y_pred, color='red', label='Predict')\n",
        "# plt.title('Testing')\n",
        "# plt.xlabel('time [days]')\n",
        "# plt.ylabel('price')\n",
        "# plt.legend(loc='best')\n",
        "# plt.savefig(param['file_name']+'_test_img')\n",
        "\n",
        "# y_pred = networks[0].predict(xTrain)\n",
        "# plt.plot(yTrain, color='black', label='Actual')\n",
        "# plt.plot(y_pred, color='red', label='Predict')\n",
        "# plt.title('Training')\n",
        "# plt.xlabel('time [days]')\n",
        "# plt.ylabel('price')\n",
        "# plt.legend(loc='best')\n",
        "# plt.savefig(param['file_name']+'_train_img')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viE5n-TT-foy"
      },
      "source": [
        "# #predict xTest and upscale y values\n",
        "# y_pred = nnet.predict(xTest)\n",
        "# y_pred_scaled = y_pred * upscale_value\n",
        "\n",
        "# yTest\n",
        "# print('Our mse error on the testing data is: ')\n",
        "# error = calc_mse(y_pred, yTest)\n",
        "# print(round(error,2))\n",
        "\n",
        "# print('Our mse error on the testing data after rescale is: ')\n",
        "# error = calc_mse(y_pred_scaled, yTest_scaled)\n",
        "# print(round(error,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUwz9BiE-ES8"
      },
      "source": [
        "# #batch dimensions\n",
        "# rows = xTrain.shape[1]\n",
        "# columns = xTrain.shape[2]\n",
        "\n",
        "# #Steps for rnn:\n",
        "# #1. initialize, #2. structure, #train, #summary, #predict\n",
        "# nnet = Rnn(rows,columns)\n",
        "\n",
        "# units = [50, 60, 80, 120] #nodes for each layer\n",
        "# dropouts = [0.2,0.3,0.4,0.5] #strength of dropouts\n",
        "# nnet.structure(4, units, dropouts)\n",
        "# nnet.summary()\n",
        "\n",
        "# print('')\n",
        "\n",
        "# #train model\n",
        "# nnet.train(xTrain, yTrain, 25, 50, 'adam', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEr0VRCH3NHW"
      },
      "source": [
        "# y_pred =networks[0].predict(xTest)\n",
        "# y_pred = y_pred * upscale_value\n",
        "# yTest = yTest * upscale_value\n",
        "# print('Our mse error on the testing data is: ')\n",
        "# print(calc_mse(yTest, y_pred))\n",
        "\n",
        "# plt.plot(yTest, color='black', label='Actual')\n",
        "# plt.plot(y_pred, color='red', label='Predict')\n",
        "# plt.title('Testing')\n",
        "# plt.xlabel('time [days]')\n",
        "# plt.ylabel('price')\n",
        "# plt.legend(loc='best')\n",
        "# plt.savefig(param['file_name']+'_test_img')\n",
        "\n",
        "# y_pred = networks[0].predict(xTrain)\n",
        "# plt.plot(yTrain, color='black', label='Actual')\n",
        "# plt.plot(y_pred, color='red', label='Predict')\n",
        "# plt.title('Training')\n",
        "# plt.xlabel('time [days]')\n",
        "# plt.ylabel('price')\n",
        "# plt.legend(loc='best')\n",
        "# plt.savefig(param['file_name']+'_train_img')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}